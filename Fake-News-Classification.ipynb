{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de313ad2-563f-4ab2-a5b0-6833de371d3f",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5fda868-b307-452d-8068-94a0d7b6cc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd          # to read and handle data (like Excel)\n",
    "import re                    # to clean text\n",
    "import nltk                  # natural language toolkit for text processing\n",
    "from sklearn.model_selection import train_test_split   # split into train/test\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # convert text → numbers\n",
    "from sklearn.linear_model import LogisticRegression   # ML model\n",
    "from sklearn.svm import LinearSVC                     # another ML model (SVM)\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6934c04-6fc5-4887-8cbd-dab6aeee1c06",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "967fbdec-79d5-4f38-a838-bfb06128c515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the two datasets\n",
    "fake = pd.read_csv(\"Fake.csv\")\n",
    "real = pd.read_csv(\"True.csv\")\n",
    "# Add labels: 0 = Fake, 1 = Real\n",
    "fake[\"label\"] = 0\n",
    "real[\"label\"] = 1\n",
    "# Combine both into one dataset\n",
    "df = pd.concat([fake, real], axis=0).reset_index(drop=True)\n",
    "# Combine title + content into a single text column\n",
    "df[\"text\"] = df[\"title\"] + \" \" + df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4106dd4-fe67-4946-b85a-e2cec08a5be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
      "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
      "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
      "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
      "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
      "\n",
      "                                                text subject  \\\n",
      "0   Donald Trump Sends Out Embarrassing New Year’...    News   \n",
      "1   Drunk Bragging Trump Staffer Started Russian ...    News   \n",
      "2   Sheriff David Clarke Becomes An Internet Joke...    News   \n",
      "3   Trump Is So Obsessed He Even Has Obama’s Name...    News   \n",
      "4   Pope Francis Just Called Out Donald Trump Dur...    News   \n",
      "\n",
      "                date  label                                         clean_text  \n",
      "0  December 31, 2017      0  donald trump sends embarrassing new year eve m...  \n",
      "1  December 31, 2017      0  drunk bragging trump staffer started russian c...  \n",
      "2  December 30, 2017      0  sheriff david clarke becomes internet joke thr...  \n",
      "3  December 29, 2017      0  trump obsessed even obamas name coded website ...  \n",
      "4  December 25, 2017      0  pope francis called donald trump christmas spe...  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0a6bdf-8522-4cab-8b34-07f69a36df29",
   "metadata": {},
   "source": [
    "## Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6146b9f-c32c-4918-b655-f297e3648e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def preprocess(text):\n",
    "    text = text.lower()                           # lowercase\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)          # remove numbers/punctuation\n",
    "    tokens = text.split()                         # split into words\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Apply to dataset\n",
    "df[\"clean_text\"] = df[\"text\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0df7d2a-f2e4-4f03-b7fb-e6abba6d1056",
   "metadata": {},
   "source": [
    "## Split into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f03d0dd-3d4e-476d-a2aa-915f03234cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"clean_text\"]    # input (news text)\n",
    "y = df[\"label\"]         # output (0 = Fake, 1 = Real)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8ecd0e-de28-4a82-b792-acf53f5c0dff",
   "metadata": {},
   "source": [
    "## Convert Text → Numbers (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bd84e97-aefd-49b9-893e-4d2401197644",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000)  # use top 5000 words\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3465fa-ccc1-48f8-a5ad-d0a2ea2d8a4b",
   "metadata": {},
   "source": [
    "## Train the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e71fba6-ae12-46fc-b44b-6057f4c6af0c",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0207fc0d-0f37-487a-a646-1782ce06b78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "Accuracy: 0.9870824053452116\n",
      "F1-score: 0.9865116279069768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.99      0.98      0.99      4696\n",
      "        Real       0.98      0.99      0.99      4284\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred_lr))\n",
    "print(classification_report(y_test, y_pred_lr, target_names=[\"Fake\", \"Real\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da581362-f123-4406-a563-5e05c507aa31",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb8ad508-acc0-487a-a051-598cd0989c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Results:\n",
      "Accuracy: 0.9943207126948775\n",
      "F1-score: 0.9940524781341108\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       1.00      0.99      0.99      4696\n",
      "        Real       0.99      0.99      0.99      4284\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model = LinearSVC()\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"SVM Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm, target_names=[\"Fake\", \"Real\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
